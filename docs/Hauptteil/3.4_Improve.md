---
layout: default
title: 3.4 Improve
parent: 3. Hauptteil
nav_order: 6
---

# Improve Phase

Da ich mit der Qualitätsmanagementmethode *Lean Six Sigma* arbeite, werde ich Schritt für Schritt den *DMAIC* Zyklus durchgehen und somit den Prozess zu bearbeiten. 

Der vierter Schritt dazu ist die *Improve Phase*. Was in dieser Phase genau geschieht, wird in der Einleitung unter Punkt 2.5 Projektmanagement-Methode beschrieben.

![Improve](../ressources/bilder/working.png){: width="250px" }

[Quelle](../Quellenverzeichnis/index.md#improve)

## Was ist Kubernetes ?

Kubernetes ist eine Open-Source-Plattform zur Automatisierung der Bereitstellung, Skalierung und Verwaltung containerisierter Anwendungen. Es ermöglicht die Orchestrierung von Containern über Cluster von Hosts hinweg und bietet Funktionen wie Load Balancing, automatisierte Rollouts und Rollbacks sowie Selbstheilung von Anwendungen. Kubernetes optimiert die Ressourcennutzung und unterstützt DevOps-Methoden durch eine nahtlose Integration in CI/CD-Pipelines. Die Plattform ist flexibel, skalierbar und unterstützt verschiedene Cloud- und On-Premise-Umgebungen, was sie zu einem zentralen Werkzeug für moderne Softwareentwicklung macht.

## Warum Kubernetes ?

Für meine Semesterarbeit verwende ich Kubernetes als Host für meine Camunda-Umgebung. Da die Umgebung automatisiert über eine CI/CD-Pipeline erstellt werden soll, bietet sich Kubernetes ideal an. Zudem behandeln wir das Thema Kubernetes in der Schule, und ich möchte mich durch dieser Semesterarbeit weiter darin vertiefen. Kubernetes bietet auch direkte Funktionen für Selbstheilung und Rollbacks.

![Goals](../ressources/bilder/kubernetes.png){: width="250px" }

## Was ist eine CI/CD Pipeline ?

Eine CI/CD-Pipeline (Continuous Integration/Continuous Deployment) automatisiert den Prozess der Softwareentwicklung, indem sie Codeänderungen kontinuierlich integriert, getestet und bereitgestellt werden.

## CI/CD mit Github Actions

GitHub Actions ist ein Tool, das diese Automatisierung direkt auf GitHub ermöglicht. Es erlaubt uns, Workflows zu erstellen, die bei bestimmten Ereignissen wie "push" oder "pull request" automatisch ausgelöst werden. Ein Workflow besteht aus "Jobs", die in "Schritten" organisiert sind und individuelle Befehle oder Aktionen enthalten.

Wie mein Workflow aussehen wird:

*Continuous Integration (CI):* Mein Workflow-Job erstellt einen Container, der die Camunda-Engine und die BPMN-Dateien enthält, und führt danach Unit-Tests aus.

*Continuous Deployment (CD):* Nach erfolgreichem Testen wird das Docker-Image in die GitHub Container Registry (ghcr.io) gepusht und dann in einer Kubernetes-Umgebung bereitgestellt und automatisch gestartet.

Die Pipeline wird über eine YAML-Datei in .github/workflows konfiguriert.


## Umsetzung (Improve)

### Erstellen und betreiben des Camunda Containers

Als erstes habe ich ein Dockerfile erstellt um ein Docker-Image zu generieren was auch eines meiner Ziele war. Dabei konnte ich ein bestehendes Docker-Image von Camunda verwenden. Das Dockerfile habe und meine BPMN und Form's Files habe ich erst auf Docker-Desktop deployed um zu repetieren wie das ganzen Camunda zu bedienen ist. Ich habe mir im Anschluss viele Recherchen betrieben und mir gedanken gemacht, wie ich meine BPMN und Form Files automatisiert auf die Camunda Engine deployen kann. Ich hatte dann auch Kontakt mit Thomas Kälin. Er hat mir vorgeschlagen, aus meinem lokan Docker-Container ein neues Image zu generieren, in welchem meine Deployten Files integriert sind. Auf diesem Weg kann ich zwar den Container komplett auf Kubernetes Deployen, die automationen in einer Pipeline wird dann aber eher schwirieg. Nach weitere Recherchen habe ich dann gesehen, dass Camunda ein Helm Chart anbietet, welches auf Kubernetes deployed werden kann. Diese Chart habe ich dann versucht auf den Kubernetes Cluster von Philipp Stark zu deployen, welchen wir währen des CNC Moduls aufgesetzt haben. Leider schien die Umgebung die das Helm Chart baut zu gross für die Umgebung zu sein. Ich habe mich dann entschieden auf das MAAS von Marcel zu wechseln. Hier musste aber erst eine Kubernetes Umgebung aufgebaut werden.

### Erstellen einer Kubernetes Umgebung mit Terraform

Wir haben während der Semesterarbeit mit dem Modul Terraform begonnen und konnten schon einige Hands on Übungen durchführen. Da mein Know how für das erstellen einer kompletten Kubernetes Umgebung jedoch noch zu klein war, konnte ich eine Vorlage von einem Klassenkollegen Yves Wetter übernehmen. In der Vorlage musste das [cloud_init_k0s.yaml](../../cloud_init_k0s.yaml), [data.tf](../../data.tf) und das [main.tf](../../main.tf) angepasst werden, damit das Deployment auf meinen Nodes ausgerollt wird. Nach dem Erstellen der Umgebung gab es aber probleme mit dem Deployen des Camunda Containers. Das Problem war, dass das Syslogfile zu gross war und gelöscht werden musste.

### Deployen des Camunda Containers und der Businessprozesse

Damit ich den Container auf die Kubernetes Umgebung deployen kann, habe ich mithilfe von ChatGPT ein [deployment.yaml](../../camunda-deployment-wpostgress.yaml) erstellt, in welchem das camunda-image in einem Contaner betrieben wird. Die Camunda-Engine ist dann über den Port 8080 über den Container ansprechbar. Der Port 8080 wird dann an den Nodeport 30000 weitergeleitet, damit ich später vom MAAS Netzwerk auf die Engine zugreifen kann.

![Webpage_Camunda](../ressources/bilder/HTTP_Camunda.png)

Nun müssen der Business Prozess auf die Engine deployen werden. In meine 2.Semsterarbeit habe ich das über den Camunda-Modeler direkt gemacht, da diese methode aber manuell ausgeführt werden muss, dient Sie dieser Semesterarbeit nicht. Ich habe aber bereits mit der REST-API Schnittstelle des Modelers im 2.Semester gearbeitet und habe dann nach einer POST-Methode gesucht. Diese fand ich schliesslich auch auf der Camunda Homepage. Nach weiteren Recherchen nutze ich PODMAN um den Post zu testen. Es zeigte mir anfangs an, dass das Deployment nicht funktioniert, weil etwas im .bpmn file nicht stimmte. Ich habe erst einige Zeit später bemerkt, dass ich beim POST nicht auf das Finale .bpmn file des 2.Semesters verwiesen habe, weshalb es mir immer den Fehler angezeigt hat. Nach anpassen des pfades für das File konnte ich schlussendlich das .bpmn file über die REST-API Schnittstelle deployen. Glücklicherweise kann man im PODMAN die Abfrage als CURL einsehen. Ich habe dann das ganze deployment mit POSTMAN vorbereitet und habe mir dann den CURL Befehl kopiert. Diese sieht wie folgt aus:

```
curl --location 'http://10.0.24.60:30000/engine-rest/deployment/create' \
--header 'Content-Type: multipart/form-data' \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Grundgeruest.bpmn" \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Anmeldeformular.form" \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Datenerfassung.form" \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Datensicherung.form" \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Defektanalyse.form" \
--form "upload=@C:\\Users\\dennis.buathong\\OneDrive\\Dokumente\\Gitrepos\\ITCNE23\\4.Semester\\Semesterarbeit\\SemArb4-CD-und-Camunda-BPM\\processes\\Abholung.form"
```
Die Dateiablage wird zu eine spätere Zeitpunkt auf Github verweisen.
Das Testing hat dann jedoch gezeigt, dass nicht alles gleichzeitig deployed werden kann, weshalb ich mithilfe von ChatGPT ein [Shellskript](../../upload.sh) erstellt habe, welches die Files nach einander Deployed (delay von 1 Sekunde). Nach dem Ausführen des Skript, wird der Businessprozess nun voll funktionsfähig im Camunda angezeigt.

![Garantiefallprozess](../ressources/bilder/running_process_camunda.png)

### Deployen einer Postgres Datenbank mit PV und PVC

Camunda speichert per default die Prozessinstanzen auf dem Host der Engine, in meinem Fall auf einem Pod. Das macht für meinen Anwendefall mit Kubernetes keinen Sinn. Ich habe herausgefunden, dass Camunda eine Postgres Datenbank anlegt und die Prozessinstanzen darin gespeichert wird. Mit ChatGPT konnte ich das [postgres-deployment.yaml](../../postgres-deployment.yaml) erstellen, damit die Prozessinstanzen auf einen separaten Postgres Pod ausgelagert werden. Das mache ich nur aus akademischen Gründen so. In einer Business Umgebung würde ich die Postgres Datenbank komplett auslagern und nicht in Kubernetes betreiben. Damit die Postgres Datenbank jedoch funktioniert braucht diese einen festen Speicher (Persistent Volume - *PV*). Dazu habe ich das [postgres-pv.yaml](../../postgres-pv.txt) erstellt. Damit das *Persistent Volume* auch benutzt werden kann, musste ein weiters deployment erstellt werden [postgres-pvc.yaml](../../postgres-pvc.yaml). Im [Postgres-deployment](../../postgres-deployment.yaml) wird dann das *PVC* gemountet. Im [Camunda-deployment](../../camunda-deployment-wpostgress.yaml) wird dann im *ENV* die Datenbank mitgegeben. Die Camunda Engine weiss nun, dass die Prozessinstanzen auf der neu erstellten Datenbank abgelegt werden muss. Der Postgres Pod wiederrum schreibt die Datenbank auf das *Persistent Volume*. Mit dieser Konfiguration können nun die Pods gelöscht und wieder neu gebaut werden. Die Daten bleiben immer auf dem *Persistent Volume*

### Anbindung der Postgres Datenbank an einen NFS-Storage

Währen dem Arbeiten habe ich bemerkt, dass die Lösung mit dem PV nicht funkioniert, weil dieser nur auf dem Node eingerichtet wird, wo die Konfiguration deployed wird. Ich musste deshalb eine [Storageclass](../../storageclass.yaml) erstellen. Ich habe dazu die Schulunterlagen von Philipp Stark verwenden [hier](https://github.com/pstark-code/kubernetes-homelab/blob/main/04-neuer-cluster/01-grund-anforderungen/nfs-storage.md). Anschliessend konnte ich das [Postgres-pvc.yaml](../../postgres-pvc.yaml)anpassen und erneut deployen. Jetzt wird Camunda immer auf die Daten zugreifen können, egal auf welchem Node der Service läuft.


### Erste CI/CD Pipeline auf Github erstellen

Um die Anpassungen der BPMN-Form Files automatisiert auf den Kubernetes Cluster zu deployen habe ich mir das Ziel gesetzt eine eine CI/CD Pipeline mit **Github Actions* zu erstellen. Da mein Cluster nicht von ausserhalb des Schulnetzes erreichbar ist, musste ich mir überlegen, wie Github auf die Umgebung zugreifen kann. Ich habe dann eine Anleitung gefunden, um einen Runner zu konfigurieren, welches mein *Personal access token* beinhaltet. Den Token musste ich erst erstellen. Wie man das macht wird in dieser [Anleitung](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller) beschrieben. Ich hatte schwirigkeiten den Runner zum laufen zu bringen [hier](../Abschluss/Erfahrungen.md#runner) wird beschrieben, wie ich das Problem lösen konnte. Nachdem der Runner erfolgreich getestet wurde konnte ich mich an die Pipeline machen. Da ich bereits im Kopf hatte wie ich die Deployment der BPMN und Form - Files umsetzen möchte, konnte ich mit Hilfe von ChatGPT relativ schnell eine erste Version der Pipeline erstellen. Nach ausarbeiten und testen dieser Version, konnte ich eine Funktionieren CI/CD Pipeline erstellen.

````
name: Deploy Camunda Files

on:
    push:
      paths:
        - 'processes/**'

jobs:
  deploy:
    runs-on: arc-runner-set

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Deploy Camunda Files
      run: |
            #!/bin/bash

            # Camunda Server URL
            SERVER_URL="http://10.0.24.77:30000/engine-rest/deployment/create"

            # URLs der .form- und .bpmn-Dateien im Git-Repository (Raw-URLs)
            FILES=(
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Grundgeruest.bpmn"
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Abholung.form"
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Anmeldeformular.form"
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Datenerfassung.form"
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Datensicherung.form"
                "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Defektanalyse.form"
            )

            # Iteriere über die Dateien und führe den curl-Befehl aus
            for URL in "${FILES[@]}"
            do
                echo "Lade Datei hoch: $URL"

                # Extrahiere den Dateinamen (mit der Erweiterung) aus der URL
                FILENAME=$(basename "$URL")

                # Herunterladen der Datei und Speichern unter dem gleichen Namen
                curl -s -o "$FILENAME" "$URL"

                # Datei an Camunda hochladen
                curl --location "$SERVER_URL" \
                    --header 'Content-Type: multipart/form-data' \
                    --form "upload=@$FILENAME"

                # Temporäre Datei löschen
                rm "$FILENAME"

                sleep 1
            done

            echo "Alle Dateien wurden erfolgreich hochgeladen."

````

Die Anpassungen werden direkt 

###  CI/CD Pipeline mit testing auf Github erstellen

Zu beginn der Semesterarbeit war geplant, ein Unit-Testing durchzuführen. Wie sich währen der Arbeit aber herausstellte, konnte ich das nicht umsetzen, da ich nicht auf den Quellcode von Camunda zugriff habe. Ich musste mir ein anderes Testing überlegen und bim zum Schluss gekommen, dass ein *End to End*-Testing sinn machen würde. Erst habe ich mir Selenium angeschaut bin dann aber auf Playwright gestossen. Den Testcase von meinem Camunda Service konnte ich dann über eine Bildschirmaufnahme erstellen [hier](./3.5_Control.md#playwright) mehr dazu. Die fertige Pipeline sieht nun so aus
```
name: Deploy Camunda Files

on: #workflow_dispatch
  push:
    paths:
      - 'processes/**'

jobs:
  deploy:
    runs-on: arc-runner-set  # Use custom runner

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Deploy Camunda Files
      run: |
        #!/bin/bash
        SERVER_URL="http://10.0.24.89:30000/engine-rest/deployment/create"

        FILES=(
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Grundgeruest.bpmn"
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Abholung.form"
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Anmeldeformular.form"
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Datenerfassung.form"
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Datensicherung.form"
            "https://raw.githubusercontent.com/Bazzako/SemArb4-CD-und-Camunda-BPM/main/processes/Defektanalyse.form"
        )

        for URL in "${FILES[@]}"
        do
            echo "Uploading file: $URL"
            FILENAME=$(basename "$URL")
            curl -s -o "$FILENAME" "$URL"
            curl --location "$SERVER_URL" \
                --header 'Content-Type: multipart/form-data' \
                --form "upload=@$FILENAME"
            rm "$FILENAME"
            sleep 1
        done

        echo "All files uploaded successfully."

  test:
    runs-on: arc-runner-set  # Use custom runner
    needs: deploy

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Install Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'

    - name: Install dependencies
      run: |
        cd tests
        npm install
        echo "npx wird installiert"
        npx playwright install --with-deps


    - name: Run Playwright tests
      run: |
        cd tests
        npx playwright test

    - name: Upload Playwright test results (optional)
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: playwright-results
        path: tests/playwright-report/
```
Da die Files direkt in der Postgres Datenbank überschrieben werden, kann man die Änderungen direkt im Camunda sehen.

### Ingress

Damit man man nun nicht direkt über eine IP-Adresse oder DNS-Namen auf einen Worker zugreifen muss und auf den Camunda Service kommt, habe ich einen Ingress eingerichtet. Da ich mit dem MAAS DNS arbeite, hatte ich die Möglichkeit nicht meine Services alle über eine IP-Adresse anzusprechen. Darum musste ich es über den Node-Name machen wie man in der Konfiguration sehen kann (host).

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: camunda-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: cloud-hf-14-w1.maas        
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: camunda-service   
            port:
              number: 8080          

```

Der Camunda-Service Container wird auf dem Port 8080 exposed. Der Service kann nun wie folgt erreicht werden: http://cloud-hf-14-w1.maas:30642/camunda. 

### Nginx Installation

Damit der Ingress funktioniert muss einer Ingresscontroller Installiert werden. Ich habe mich für Nginx entschieden, da wir damit bereits in der Schule gearbeitet habe. Ich habe dazu die Vorlage/Anleitung von Philipp Stark verwenden. [Link](https://github.com/pstark-code/kubernetes-homelab/blob/main/04-neuer-cluster/01-grund-anforderungen/ingress.md)

